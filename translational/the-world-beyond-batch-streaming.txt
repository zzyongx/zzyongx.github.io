批处理之外：Streaming 101
   现代数据处理概念高级巡览

（备注：本文译自 http://radar.oreilly.com/2015/08/the-world-beyond-batch-streaming-101.html）

如今，Streaming 数据处理是大数据中至关重要的部分，原因如下：
* 商业渴望更及时的数据，使用流处理可以提供更低的延迟。
* 现代商业海量无界数据不断增加，非常普遍，使用为无限数据设计的系统更易于分析这些数据。
* 及时处理产生的数据，把负载均匀的分布在所有时间，资源的消耗更加平稳和可预测。

尽管商业驱动对流处理的研究激增，现在主要的流处理系统和批处理相比，还相对不成熟。这导致这个领域的开发很活跃，有很多让人激动的成果。

作为一个在Google从事了至少5年海量可扩展流式系统研发的人，毫不夸张的说，流处理的时代思潮使我欣喜。我很想让大伙儿了解，流式系统可以做什么，如何最好的使用它，特别是考虑到现在，多数流式处理和批处理之间，在语义上存在鸿沟。因为要写的东西比较多，我把它分成两篇。
1. Streaming 101：这是第一篇，主要讲时域和常用的数据处理方法，包括批处理和流处理。在深入时域有关的细节前，会给出一些基本的背景信息和理清一些术语。
2. The Dataflow Model：第二篇，主要讲Cloud Dataflow 使用的同一模型（batch和streaming），借助具体的例子，讲它在不同用户场景下的使用。最后对现在的批处理和流处理系统，做简单扼要的语义比较。

好了，罗嗦的开场不太得体，让我们开始吧。


1. 背景
首先，我将讲一些重要的背景信息，这些信息有助于给我想讨论的东西一个框架。我们分三部分介绍它们。
* 术语：为了准确讨论复杂话题需要准确的定义术语。对于当前有多个意思的术语，我将确定下我对他们的定义。
* 能力：我将讨论流系统经常被提到缺点。我还将提出我的观点，我相信，为了解决不断发展的现代数据消费需求，数据处理系统构建者应采纳这些观点。
* 时域：我将介绍数据处理有关的两个主要时域，展示它们的关联，指出这两个时域带来的困难。


1.1 术语：什么是流
在作任何进一步讨论前，我想先解决一个问题： 什么是流？现今，术语“流”被用来表示很多不同的东西（到目前为止，图简单，我多少也有些随意使用），这可能让人错误理解流真正是什么，或者流系统实际能胜任什么。因此，我想先较准确的定义什么是“流”。

问题的关键在于，很多应该被描述为“他们是什么”（例如：无界数据处理，近似结果）的东西，常常在口头上被描述为“他们以前是如何被实现的”（例如：通过流执行引擎）。由于缺乏“流到底是什么”的精确定义，拖累了流系统，提到流系统，往往隐含着近似的或推测的结果。考虑到设计良好的流系统，完全可以像批引擎一样提供正确的，一致的，可复现的结果，我给流系统赋予非常明确的含义：“一类被设计来处理无限数据集的数据处理引擎”。如此而已。（出于完整考虑，定义包含真正的流和微批实现）（备注：每个批处理足够小和及时，就是流处理）

下面是一些“流”相关的，我经常听到的术语，这里给出更确切的描述。
* 无界数据：“一类一直增长的，本质上无限的数据集”。他们经常被称作“流数据”。然而，用“流”或者“批量”来称呼数据集是有问题的，就像上面说的，他们隐含了使用特定的执行引擎来处理他们。事实上，这两类数据的关键不同在于是否有限，应该使用这个不同来定义他们。我更愿意称无限的“流数据”为“无界数据”，有限的“批数据”为“有界数据”。

* 无界数据处理：一个不断发展的数据处理模型，用来处理前面提到的无界数据。尽管我个人喜欢术语“流”来描述这类数据处理，但在这个场景，它再次隐含了，它使用流执行引擎，这是有误导性的。当批系统刚出来时，曾（通过反复运行）被用来处理无界数据。（相反的，设计良好的流系统能胜任处理有界数据）。为清楚起见，我用无界数据处理来称呼它。

* 低延迟，近似或者推测的结果：提到此类结果，通常意味是流引擎计算的结果。事实上，只是批处理系统没有被设计为低延迟和近似结果，这是人为设计的，没有什么必然性。当然，如果需要，批处理引擎完全可以产生近似结果。所以说描述结果什么（低延迟的近似的），比说它们是如何获得的（通过流引擎计算）要好。

从现在起，当我提到“流”，我只是在说被设计来处理无界数据的执行引擎而已。如果我要表述上面的概念，我会用无界数据，无界数据处理或低延迟/近似/推测结果明确表示。以上是我在Cloud Dataflow中采用的术语，我希望其它人也使用类似术语。


1.2 那些关于“流”的被夸大的限制
下面，让我们谈谈流系统能做什么，不能做什么，重点谈能做什么。通篇，我想强调的最重要的事是，设计良好的流系统能做什么。过去，往往为得到低延迟的计算结果才用流系统，但它只能得到近似结果，所以需要辅以更强大的批处理系统得到最终正确的结果，就像Lambda Architecture做的那样。

Lambda Architecture的基本思想是，同时运行流处理系统和批处理系统，两者做本质上相同的运算。流系统提供低延迟的，不精确的结果（无论是使用了近似算法，还是流系统本身无法得出精确结果），随后，批处理计算完成，提供精确结果。这个思想是Twitter的Nathan Marz（Storm的创建者）提出的，它非常成功，因为它是当时最好的方法。流引擎的弱点在于精确度，而批引擎很笨重，Lambda让两者协同，利用流引擎的低延迟和批引擎的精确性。遗憾的是，维护Lambda非常麻烦。你需要构建，提供，维护两套独立的工作流，还要合并他们的结果。

多年来，我一直致力于“强一致”流引擎的研究，我觉得Lambda的整个理念有点讨厌。不出意外的，当Jay Kreps的文章Questioning the Lambda Architecture出来时，我成了它的超级拥泵。他是第一个旗帜鲜明的质疑双系统执行必要性的人。通过引入类似Kafka的可重放系统作为流连接器，解决重复性问题。Kreps甚至提出了Kappa Architecture，通过为手头的工作构建设计良好的系统，只需要一条工作流。虽然我不认为这个观点需要一个名字（Kappa Architecture），但我大体上支持这个观点。

实际上，我更激进，我认为设计良好的流处理系统提供的功能，是批处理功能的严格超集。Modulo perhaps an efficiency delta(1)，最终将不需要批处理。荣耀归Flink开发者们（Flink同时支持流和批量数据处理），Flink贯彻了这个思想，它的核心是“总是流处理”，即使在batch模式下，也是如此。太爱它了。

随着流系统的广泛成熟，加上无界数据处理框架的稳定，最终类似Lambda Architecture这样的无奈选择，将成为大数据历史中的古迹。我相信实际已经成熟，只要两个条件，流式处理就可以在批处理擅长的领域击败批处理。

1.2.1 正确性 - 如此可以和批处理势均力敌
核心是，正确性归结为存储一致性。流处理系统需要方法不断给持久状态设置检查点（Kreps在他的文章 Why local state is fundamental primitive in stream processing），即使在机器宕机时仍然保持一致性。几年前，当Spark第一次出现在大数据领域时，它的一致性特性就像黑暗的流处理世界的一座灯塔。谢天谢地，从此后，事情已经变好很多。值得主意的是，仍有很多流处理系统得过且过，完全没有强一致性。难以值信，一次性处理仍然是个事儿，但它的确是。

一致性太重要了，让我重申一下。一次性处理需要一致性，正确性需要一致性，任何想赶上或这超批处理系统能力的系统需要一致性。除非你真的不关心结果，不然，我请求你避开任何不提供强一致性状态的流处理系统。批处理系统不需要提前确认是否能提供正确结果，别浪费时间在达不到这个标准的任何流处理系统上。

如果想了解更多关于如何在流处理系统中保持强一致性，建议你翻阅MillWhell或Spark Streaming的论文。这两篇论文花了很大篇幅讨论一致性。

1.2.2 时间推演工具 - 如此可以超越批处理
好的时间推演工具对处理无界，无序（各种事件时间偏移）数据是必须的。不断增加的数据集呈现出无界，无序的特点，现存的批处理系统（多数的流处理系统）缺乏必要的工具解决无界无序带来的困难。本文剩下部分和下一篇文章，我主要聚焦并解释这个问题。

首先，我们需要对为什么时域这么重要有个基本概念，然后深入探讨什么是无界无序数据，最后看一个处理有界无界数据的常见方法，无论是使用批处理还是流处理，方法都通用。


2 事件时间 vs 处理时间
为了深切讲述无界数据处理，需要对其中牵扯的时域有清晰认知。在任何数据处理系统中，有两类典型的时域我们比较关心：
* 事件时间，事件实际发生的时间
* 处理时间，系统感知到事件的时间

不是所有人都需要关心事件时间（如果你不用关心，那就太好了），但大部分都要 。仅举几例，用户行文随时间变化的特征，记账应用，大部分的异常行为检测。

理想情况，事件时间和处理时间应该总是相同的，事件一发生即被处理。然而，现实不是这样。事件时间和处理时间的偏移常常不是零，而是底层数据源，执行引擎，硬件等这些因素特征的高阶函数。影响偏离程度的因素包括：
* 共享资源的限制，例如网络拥塞，网络分割，非专用系统上共享CPU等
* 软件问题，例如分布式系统逻辑，竞争等。
* 数据自身的特点。例如，key的分布，吞吐量变化，混乱程度的变化（例如，一群下飞机的人一起打开手机网络）

结果，把现实中的事件时间和处理时间做成图，大概像下面这个样子。

<img src="http://s.radar.oreilly.com/wp-files/2/2015/08/Post01_Fig01_TimeDomains.jpg" />

斜率为1的黑线表示理想情况，处理时间和事件时间一样。红线代表实际情况。此例中，一开始处理时间落后于事件时间，中间转向贴近理想情况，最后又开始落后。红线和黑线的水平距离表示处理时间和事件事件的偏差。偏差主要是处理延迟导致的。

因为事件时间和处理时间的关系不是不变的，这意味着，如果你关心事件时间（事件究竟是什么时间发生的），就不能仅仅依赖数据是何时出现在系统中的，来分析它。遗憾的是，这是很多为处理无界数据而设计的系统的工作方式。为了应对无界数据的无限性，这些系统往往提供了某种意义上的输入数据窗口。后续会深入探讨窗口的事情，但它本质上是把数据分成临时的有界有限数据。


如果你关心正确性，并且在事件时间背景下分析数据，你不能向多数现有系统一样，使用处理时间来定义临时边界。可以说，由于处理时间和事件时间间缺乏稳定的关联，一些事件时间会被放到错误的处理时间窗口（因为分布式系统固有的延迟，很多输入数据的在线/离线特点等），一些正确的事件时间会被排斥在外。 下文和后一篇文章会通过一些例子，了解这个问题的更多细节。

不幸的是，即使使用事件时间来划分窗口，结果也不乐观。在无界数据背景下，乱序和各种偏差引入了事件窗口的完成性问题，在缺乏事件时间和处理时间的可预见的关系时，如何确定某个事件时间点的全部数据都接受完了。对现实中的多数数据源，你就是不能。当前在用的大量主流数据处理系统依赖某种意义的完成性，这让他们在处理无界数据时有严重的缺陷。

我的意见是不要把无界数据划分成最终可完成的有限批量信息，我们应该设计工具，让我们能够应对现实世界的复杂数据带来的不确定性。新数据会来，老的数据会被删除或更新，我们应该设计系统，它自身可以处理这些情况，概念上的完成性应该是一种优化，而不是语义上的必须。

在深入探讨，如何借助Cloud Dataflow的Dataflow来构建这样一个系统前，让我们再多了解点背景知识：常见的数据处理模式。


3. 数据处理模式

