如何用最简单的话介绍paxos算法
paxos算法是分布式系统里一个很基础的算法，理解起来不是很简单，下文译自：http://www.quora.com/Distributed-Systems/What-is-a-simple-explanation-of-the-Paxos-algorithm

为了容易理解paxos算法，最好是和其它算法对比，这些算法在解决一致性问题上有缺陷，而paxos解决了这些缺陷。

（备注：笼统的说，paxos算法要解决分布式系统中的一致性问题。“一致性问题”很容易联想到分布式系统中的“强一致性，最终一致性”等，但paxos里的一致性偏重于参与者就某个取值达成“一致性”，paxos的第一篇论文“兼职议会”（part-time parliament）很形象，议会最终要就某个问题达成一致意见。如果是全职议会，大家聚在一起开会，根据少数服从多数原则，肯定能达成“一致”。但如果是兼职的，开电话会议，信号好不好，议员有没有时间参加，正在参会的议员会不会突然吃饭去了，如何告知其它缺席议员决议，问题就很复杂了。这很像分布式系统，网络会出故障，机器会宕机等。推荐阅读：Paxos Made Simple，本文只是说了paxos算法的步骤，但缺乏相关证明，证明可以在此文中找到。，这篇中文也是不错的参考：http://www.cnblogs.com/fxjwind/archive/2013/04/11/3014620.html）

想象结婚双方婚誓的场景（很直观）：
1. 牧师分别问新郎新娘，你愿意嫁（娶）？，男女分别回答：我愿意。  （准备）
2. 牧师，我现在宣布你们结为夫妇。                                   （达成一致）

这里的婚姻发生在两人之间，假如多于两人呢？比如Aiel族中的姐妹，要么娶他们两个，要么一个都不娶，会发生什么事？如果其中一个女孩儿不说“我愿意”，那婚礼就没法进行下去。

计算机中把婚誓的场景称作“两阶段提交”


两阶段提交（2PC）
1. 投票阶段。协调者把一个建议的值发送给所有参与者，并收集它们的响应（同意或者拒绝这个值）。在分布式数据库中，协调者问其它资源管理者，是否可以提交事务，其它资源管理者回复“能”或者“不能”。
2. 提交阶段。如果“所有”参与者都同意，那么协调者告诉所有参与者，刚才的建议值就是最终的，如果有“一个”参与者不同意，协调者要告诉参与者，刚才的值不是最终的。在分布式数据库中，协调者告诉参与者“提交（commit）”或者“中止（abort）”

注意，这里参与者只能给协调者“建议的值”投票，参与者只能说“同意”或“不同意”，而不能提出自己的“值”。如果参与者想提议自己的“值”，只能发起 2PC（把自己变成协调者）。这样可以工作，但效率不高，由N个参与者组成的系统，需要3N条消息（提议，投票，决议）。

（备注：但同一时刻应该只有一个协调者，如果同时有两个协调者建议不同的值，如何达成一致？）

正常情况这个算法工作很好。但如果参与者或协调者崩溃了呢？假如，在投票阶段，协调者把建议的值发给部分参与者后崩溃了，这时会发生什么？
* 收到请求的参与者开始2PC，但是协调者崩溃了，他们会一直等待“提交阶段”。没收到请求的参与者，则压根不知道其它参与者有2PC开始。
* 参与者在投票后，可能已经锁住了一些资源。因为协调者可能恢复，所以超时都很困难。

如果在提交阶段，协调者把“决议”发给部分协调者后崩溃了，也会发生类似的问题。一些问题可以通过冗余协调者解决，当协调者失败时，冗余协调者充当协调者，试图恢复2PC，但冗余协调者也可能失败。基本上来说，在参与者或协调者故障时，2PC是不稳定的。


三阶段提交（3PC）
2PC的主要问题是，当协调者崩溃时，没人有足够的信息来完成2PC。这可以通过引入额外的步骤来解决。
1. 投票阶段，同2PC
2. 预提交，新引入的。如果所有参与者同意提交，协调者发出“预提交”消息，此时参与者可以做一些可以“回滚”的操作，不可以做不能“回滚”的操作。每个参与者回复协调者，确认“预提交”。
3. 提交阶段，很像2PC的提交。如果协调者收到所有参与者确认“预提交”，它发消息给参与者，让他们提交。如果没有收到全部“预提交”确认，协调者中止事务。

现在如果协调者在任一时刻崩溃，任一参与者可以接替协调者，从其它参与者查询现在的状态。
1. 如果参与者向替补协调者汇报，它没有收到“预提交”消息，替补候选者可以判断出，没有任何参与者“提交”了，这时可以“中止”或者“重启”事务。（备注：这也是要求预提交阶段只能做可以“回滚”操作的原因）
2. 如果参与者在“提交阶段”崩溃了，我们知道其它参与者收到并确认了“预提交”，不然不会有参与者到了“提交阶段”。这样，替补参与者可以继续处理第三阶段。

在参与者或协调者崩溃时，3PC也工作的很好，虽然额外的步骤导致延迟较大。

然而当面对网络分割时，3PC不能正常工作。假如，在参与者收到“预提交”后发生网络分割，被分成了两部分，每一部分选择了一个替补协调者，可能继续或中止事物，当网络恢复时，系统处于不一致的状态。


Paxos - 为啥还要费那劲？
既然有了3PC，我们还需要更好的协议吗？3PC唯一的问题是“网络分割”，真的吗？先让我们假设“网络分割”是唯一问题（很快会看到，显然不是）。在“网络分割”时仍然保持正确，是个值得解决的问题吗？如今，伴随着云计算和跨网服务的发展，计算节点可能分布在大陆的不同地方，甚至跨越大洋，我们的确需要一个在“网络分割”时也能正常工作的算法。

第二，网络分割不是唯一的问题。尽管我们把节点（参与者或协调者）失败看作永久失败，但更一般的情况是，节点崩溃，然后从崩溃的地方恢复。“失败-恢复”通常表现为“异步网络”模型，节点响应时间是没有上限的，永远不能确定节点是不是死掉了，他们可能只是慢，或者只是网络慢。3PC模型不能超时。

3PC是“失败-停止”适应的，但不是“失败-恢复”适应的。不幸的是，现实需要“失败-恢复”，我们需要更通用的解决方案，这是需要Paxos的原因。


Paxos是如何工作的？
Paxos的基本步骤和2PC很相似
* 选择一个节点作为Leader（Propser）
* Leader选择一个值，然后发accept-request消息给所有节点（Acceptors），Acceptors回复reject或accept
* 当多数Acceptors回复accept，达成一致，Leader发commit消息给所有节点。

Paxos和2PC的不同在于，2PC需要所有节点同意，Paxos只要多数节点同意就行。这一点很有意思，后续任何“多数节点集合”必然包含现在这个“多数节点集合”中的一个，（因为两个“多数节点集合”必然有交集）。这保证了，一旦“多数节点”就某个值（V）达成一致，后续任何节点提议其它值必然从其它节点学到这个值（V），并同意这个值（V）。这意味着即使有半数节点失败，Paxos也不会阻塞。

（备注：Leader提议其它值，根据系列规则，Acceptor可以建议自己的值，最后达成一致的值肯定是之前达成一致的某个值，如果有的话）

当然，Leader自己可能失败，为了处理情况，Paxos并不要求在某个时刻只有一个Leader。它允许任何一个节点把自己作为Leader，并且试着协调事务。这个意味着，在指定时刻，存在不止一个节点，认为自己是Leader。在这种情况下，不同Leader可能提议不同的值，此时如何达成一致呢？为此，Paxos引入了两个机制。
* 给Leader添加顺序。这样，每个节点可以辨认出当前节点和之前的Leader，从而阻止之前的Leader（可能是从失败中恢复的）破坏已经达成的一致。
* 限制Leader对提议的值的选择。一旦一致性达成（值V），Paxos强制以后的Leader只能选择值V，确保一致性的延续。这是通过让Acceptors发送最近达成一致性的值和Leader发送的提议号实现的。Leader可以从Acceptors发送的值中选择一个，如果Acceptos没有发送任何值，Leader可以用自己提议的值。（备注：后面有详细步骤）


协议步骤（分两个阶段）
1. 准备阶段
* 一个节点被选为Leader，Leader选择提议号x和值v，创建提议P1(x,v)，把提议发给所有的acceptors，等待多数节点返回。
* Acceptor收到提议P1(x,v)后
* * 如果这是Acceptor要同意的的第一个提议，回复agree。并且拒绝以后收到的提议号 < x 的提议
* * 如果已经有Acceptor同意的提议了，假设同意过的提议号最大的提议是P2(y,v2)
* * * 如果 x < y，回复 reject
* * * 如果 x > y, 回复 agree 和 P2(y,v2)

2. 接受阶段
* 如果多数Acceptors失败，或者回复reject，Leader 放弃提议，或者重启提议
* 如果多数Acceptors回复agree，Leader也知道了Acceptors已经同意了的提议。Leader从中挑选一个值（如果没有，使用自己提议的v），发送 accept request 消息，提议号和值（x，v3）。
* 当Acceptor收到accept request时，如果满足下面两个条件回复accept，否则回复reject。
* * v3和以前接受过的任何一个提议的值相同。
* * x比曾经同意过的最大的协议号大。
* 如果Leader没有收到多数accept，放弃提议并重启提议。如果收到多数accept，这轮协议结束。作为优化可以发送commit给Acceptors（告知这轮协议结算）

（备注：从协议看出，为了保证成功率，提议号x必须是单调递增，全局最大的，分布式环境下，如何保证这个就是个问题，如果提议失败，可以选择更大的提议号重试）

Paxos 错误处理
如果指定Paxos中只有一个Leader，并且要全部Acceptor同意，就成了2PC。2PC是Paxos的一个特例。

如下所示，Paxos比2PC的容错性更好
* Leader失败，另外的Leader可以发起提议
* 原来的Leader恢复，因为只同意提议号最大的提议，并且只同意之前同意过的值，所以两个（多个）Leader可以共存。

Paxos同样比3PC更容错，特别是在“网络分割”容错上。在3PC中，网络分割的每个部分分别就某个值达成一致，当分割消失时，产生了不一致。因为要多数同意，这个问题不会发生在Paxos中。除非某个分区有多数，否则不会达成一致性。如果一个分区有多数，并且就某个值达成了一致，当分区消失时，这个值也会被其它分区接受。

（备注：不是很明白，3PC时，应该需要全部节点，而不是网络分区中的全部节点同意，所以网络分割时，应该达不成任何一致性才对。Paxos发生分区时，是全部节点的多数，而不是分区中的多数）

Paxos的一个问题是，当两个Leader因为网络分割感知不到对方时，因为提议失败，交替增加提议号，导致一轮Paxos协议一直不结束。

（备注：Paxos Made simple 2.4 有这个问题的详细描述）

这是safety和livness的折中。Paxos是安全的算法，一旦一致性达成，达成的值不会变。但是Paxos不保证live，存在极端情况Paxos不会结束。事实上异步一致性算法不能同时保证safe和live。这被称作 FLP Impossibility Result。
