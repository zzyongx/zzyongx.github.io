如何战胜CAP理论
  @zzyongx
（备注：本文译自 http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html。虽然没有明确指出，但本文讲的就是人们称为Lambda Architecture的东西，目前主要用在大数据领域。但是作者的野心显然不止于此，它想让该架构应用到任何数据系统。只要预知查询模式，就可以通过大数据处理预先计算出结果。一方面是该架构的“最终一致性”太差强人意，另一方面构建“不可更改”的数据模型本身也比较复杂。文章下面的评论有一点比较有意思，说银行系统是可用性大于一致性的，这个和通常的理解相悖。另外，作者说的不可变数据，其实就是Event Sourcing。）

CAP理论表明数据库系统不能同时保证一致性（C），可用性（A）和分区容忍性（P）。但是你不能牺牲分区容忍性，所以只能在可用性和一致性间做折中。如何折中是NoSQL思潮的核心。

一致性意味着，成功写入后，任何后续读都能读到这次写。可用性意味着，系统总是可读写的。在发生网络分区时，一致性和可用性只有一个性质能够满足。

倾向于一致性的系统不得不处理一些很笨重问题。当数据库不可用时怎么办？你可以试着缓存这些写，如果缓存所在的机器不可用了，这些数据可能就丢失了。同样，这些缓存的写是不一致的一种形式，因为客户端认为写成功了，但是数据却不在数据库里。当系统不可用时，你也可以选择返回错误。如果你使用一款总是让你“稍后重试”的系统，你就明白这有多恶劣。

另外可以选择可用性优先。这些系统提供的最好的一致性是“最终一致性”，如果你使用最终一致性的数据库，在你刚写入后，你可能读到和刚才的写入不同的结果。有时，多个客户端同时读同一个key，也可能得到不同的结果。更新可能没有传递到所有的副本，所以不同副本得到了不同的更新。当检测到数据分叉时，需要客户端修复它，这需要使用时钟向量跟踪历史修改，并且合并这些更新，这就是所谓的读修复。

（备注：还有一种可调一致性，例如三副本写入两个副本才算成功，读取的时候读取两个副本总有一个是最新的。（如何判断最新是另一个问题，粗超的方法是用时间戳））

我相信在应用层维护最终一致性对开发者来说，是不可承受的负担。读修复相关代码极可能引入错误。如果有错误，错误的读修复可能给数据库带来不可逆转的破坏。

如此看来，牺牲可用性有问题，牺牲一致性对构建应用来说又太复杂。但是又只有这两个选择，真是做也是错，不做也是错。无法改变CAP的性质，还有别的可能的选择吗？

确实有。你无法躲避CAP理论，但是你可以隔离它的复杂性，防止它破坏你构建系统的能力。CAP之所以能带来复杂性，是我们构建系统的方法中，存在一些特征。两个典型的特征是，我们使用可变状态，并且使用增量算法更新这些状态。这些问题相互作用，CAP由此带来复杂性。

在本文中，我将展示一种系统设计方法，通过阻止CAP理论带来的复杂性来战胜它。不止于此。CAP是关于机器错误容忍度的结果，但人为错误容忍度比机器错误容忍度更重要。软件开发中唯一能确定的是，开发不够完美，bug不可避免的被引入系统。我们的数据系统必须能够适应有bug的程序写坏数据。我将展示你所能得到的最大的人为错误容忍度。

此文将挑战你对如何构建数据系统的基本设想。通过打破常规，重新想象数据系统应如何构建，我们将得到比你曾想过的更优雅，更可扩展，更健壮的架构。


什么是数据系统？
在讨论系统设计前，让我们先定义我们要解决的问题。数据系统的目的是什么？什么是数据？如果我们不能给这些问题，一个清晰的，囊括了所有数据应用的定义，我们甚至无法接近CAP（更别提战胜它了）。

数据应用，囊括了存储，提取，连接，聚合，流处理，持续计算，机器学习等等。给这些数据系统一个简单的定义，并非显而易见，似乎这些数据的范围分叉太多，难以用单一概念定义。

然而，看着个 Query = Function（All Data），就是它了。这个方程代表了所有领域的的数据库和数据系统，所有领域的，包括过去50年的关系数据库，索引，OLAP, OLTP, MapReduce, ETL，分布式文件系统，流处理系统，NoSQL等等，以这样或那样的方式被这个方程概括了。

数据系统回答关于数据的问题。这些问题被称作查询。这个方程表明，查询只是你拥有的全体数据的函数。

这个方程可能看起来太通用了，以至于没啥用处。它似乎没有抓住数据系统设计的任何复杂性。但关键是，它囊括了所有数据系统，这个方程是我们探索数据系统的起点，这个方程最终引导我们战胜CAP理论。

这个方程有两个概念，数据和查询。这两个不同的概念在数据库领域经常被合在一起，现在让我给出它们的严格定义。


数据
先说数据。一片数据是一个不可分割的单元，你认为它是真，只是因为它存在。这有点像数学中的公理。

数据有两个值得注意的重要性质。一，数据本质上是基于时间的。数据是你在某个时间点认为它为真的事实。例如，Sally编辑它社交应用的个人信息，说她在芝加哥。只是在她编辑信息时，你知道她在芝加哥（这条信息只有她编辑的时候是真的，她可能离开了芝加哥，但没及时更新）。假设，稍后几天，Sally更新她的个人位置是亚特兰大，然后你就知道她当时居住在亚特兰大。她现在居住在亚特兰大的事实并不能改变她过去居住在芝加哥的事实。这两条数据都是真的。

可以从第一个立即明白第二个，数据内在是不可变的。因为数据和时间密切相关，它真过就永远真。你不能回到过去，去改变数据的真。这意味着你只可以对数据做两类操作，读和创建。CRUD 成了 CR。

我忽视了“更新”操作，因为更新不可变数据无意义。例如：“更新”Sally的位置信息仅仅意味着添加一条新数据，她最近居住在一个新地方。

我也忽视了“删除”操作，同样，多数删除可以从创建新数据角度理解。例如，Bob不再关注Mary的Twitter，并不能改变他曾经关注过她。不是删除“他关注她”，而是新增“他不再关注她”。

的确有少量需要永久删除数据的情况，例如，制度要求一定时间后清除数据。这个设计可以很容易支持这个需求，为简单起见，我们先忽略这些需求。

（备注：如何设计只读数据是个问题）


查询
查询是方程里的第二个概念。查询是数据的推导。从这个意义看，查询像个数学理论。例如，“Sally现在住哪”是个查询，通过返回最近Sally的位置信息“计算”这个查询。查询是所有数据的函数，可以做任何计算，聚合，连接不同的数据等等。这样，你可以查询你服务的女性用户数，或者查询微博最近几小时的话题趋势。

我把查询定义为所有数据集的函数。当然，不是所有查询都需要用到全部数据，可能部分数据就够了。但是，重要的是，我的定义囊括了所有可能的查询，如果我们要击败CAP，我们就必须能定义任何查询。


战胜CAP理论
计算查询最简单的方法是，在所有数据集上挨个运行查询函数。如果延迟不是问题，那么已经完事儿了。

当然，想让函数在所有数据集上快速运行完是不可能的。很多查询，尤其是在线业务，需要毫秒级的响应时间。然而现在，让我们先假设可以在很短的时间完成，让我们看看这样一个系统跟CAP理论的关系，你将很快看到，这个系统不止战胜了CAP，简直是消灭了它。

CAP理论仍然存在，你仍需要选择一致性或可用性。美妙的地方在于，一旦选择了偏向哪个，就完事儿了。通过不可变数据和从头计算，避免了常常由CAP理论带来的复杂性。

如果偏向一致性，和以前没啥大变化，你有时会无法读写，因为可用性被牺牲掉了。但是，对于坚持一致性是必须的情况，这也是个选择。

如果偏向可用性，就有意思了。此时，系统是最终一致的，却没有任何最终一致的复杂性。因为系统是高可用的，你总是可以写入新数据和做查询。在失败时，查询结果不包含先前写入的数据。最终数据会一致，查询会把这些数据合并到计算结果中。

关键在于数据是不变的，数据不变意味着没有更新之类的事情，所以同一份数据不会在不同副本间不一致（备注：创建时导致的不一致呢？）这意味着不会有值分叉，不需要时钟向量或读修复。系统里只有数据和定义在数据上的函数。不需要花功夫保证最终一致性，最终一致性也不会成为构建系统的障碍。


先前，增量更新和CAP理论相互作用，导致了复杂性。增量更新和CAP理论不相容。在最终一致性系统中，可变变量需要读修复。通过拒绝增量更新，接受不可变数据，每次都从头查询，可以避免复杂性，战胜CAP理论。

当然，刚才所述只是理论上的尝试。尽管我们想每次查询，都从头计算，但这是不现实的。然而，我们已经得知了一个真正解决方案的关键性质，它应该像下面这样：
1. 系统应该很容易存储和扩展不可变的，持续增长的数据。
2. 系统的主要写操作是增加新的不可变数据。
3. 通过从头计算查询避免CAP带来的复杂性。
4. 通过增量计算降低延迟到可接受的水平。

让我们开始探索吧！记住，从现在起，所有一切都是优化。数据库，索引，ETL，批计算，流处理，所有这些都为了优化查询，将延迟降低到可接受的程度。这是简单却深刻的领悟。数据库是数据管理系统的核心，但它们也是更广层面的一部分。


批计算
找出方法，让任意数据集上的任意计算运行的很快，是一个令人生畏的问题。让我们放宽限制，可以在过时几小时的数据上做查询，如此，就有简单，优雅，通用的方案来构建数据系统。后面，我们会扩展这个方案，限制就不需要放宽了。

因为查询是所有数据的函数，最简单的，让查询快速的方法是预计算它们（备注：如何预知所有的查询呢？）。当有新数据时，从新计算所有数据。这时可行的，因为我们允许数据有几小时的过时。下面是数据流示意图。

<img src="http://static1.1.sqspcdn.com/static/f/621062/14587678/1318378913340/precomputation.png?token=72Lnlu06%2BVoX9xDYt45vdV0McfU%3D">

为了构建它，你需要一个系统：
1. 可以很容易存储大量的，持续增长的数据
2. 有可扩展的方法，在所有整个数据集上做运算

这样的系统是现成的，它成熟，经过上百组织实战测试，并且有大的工具生态系统，这就是Hadoop。Hadoop不是完美的，但它是当今批处理最好的工具。

很多人会告诉你，Hadoop仅仅擅长非结构化数据，这是完全错误的。Hadoop对结构化数据也是极好的，借助Thrift或者Protocol Buffer这样的工具，你可以存储富模式的、模式可演化的数据。

Hadoop由两部分组成，一个分布式文件系统（HDFS）和一个批处理框架（MapReduce）。HDFS擅长以可扩展的方式在文件中存储大量数据。MapReduce擅长以可扩展的方式在刚才的提到的数据上做计算。这些系统完美匹配我们的需求。

我们把数据扁平化的存在HDFS的文件中。一个文件包含一系列数据记录。为了添加新数据，你只需要在当前目录创建包含新文件，它包含了所有新数据。以这种方式存数据解决了“存大量的，持续增长的数据”的需求。

在数据上预计算查询同样直白。MapReduce是一个表达力很强的范式，几乎任何函数都可以被实现为一系列的MapReduce任务。像Cascalog，Cascading和Pig这样的工具，让实现这些功能更简单。

最后，你需要索引预计算的结果，使得可以被快速访问到。有一类数据库，非常擅长这个。ElephantDB和Voldermort read-only是专门为Hadoop导出key/value数据，快速查询用的。这些数据库支持批量写和随机读，但是不支持随机写。数据库的大部分复杂性都是随机写导致的，通过不支持随机写，这些数据库变得非常简单。例如ElephantDB，只有几千行代码，因为简单，所以非常健壮。

看个例子，批处理系统是如何的合适。假设你要构建一个网页分析程序，它跟踪页面访问，可以快速查询某个时间段（假设一个小时）的页面访问次数。

<img src="http://static1.1.sqspcdn.com/static/f/621062/14587737/1318378968643/batch_workflow_example.png?token=ynlMUUL8mou1wKb3X4jopXrStl0%3D">

这非常容易实现。每条记录包含一次页面访问，这些数据以文件的形式放在HDFS中。通过一系列MapReduce任务，一个函数统计每小时每个页面的访问次数。最终的结果是key/value对儿，其中key是 [URL, hour]，value是每个页面某小时的访问量。这些key/value对儿被导入到ElephantDB中，应用可以快速访问任何 [URL, hour] 的值。当需要访问一个时间段儿的值，通过查询每个小时的值，然后加起来，就得到最终结果。

批处理可以在任何数据集上做任何运算，唯一的缺点是数据有几小时的过时。这里的“任意”意味着可以用来解决任何问题。更重要的是，它简单，易理解，并且是完全可扩展的。你只需要考虑函数和数据，Hadoop来完成并行计算的事。


批处理系统，CAP，和人为错误容忍
到现在一起都好。那么，刚才描述的批处理系统跟CAP关系如何，是不是实现了容忍人为错误？

先说CAP。批处理系统是最终一致的，虽然有点极端，查询到的常常是几小时前的数据，但是它最终还是一致了。你只需要考虑数据和数据之上的运算，没有读修复，没有并发，也没有其它复杂性的东西要考虑。

然后是容忍人为错误。批处理系统的人为错误容忍读是你所能得到的最好的程度。此类系统，你只有两类错误可犯，一是部署了有bug的查询实现，二是写入了坏数据。

如果部署了有bug的查询实现，只需要修复bug，重新部署，重头计算，就可以了。因为查询是纯函数（没有副作用的意思）。

类似，写入坏数据的恢复方法也很显然，删除坏数据，然后重新计算。因为数据是不可变的，数据是追加写入的，坏数据不会覆盖或者破坏已经写入的好数据。这和多数传统数据库截然相反，这些数据库写入新数据就丢失了老数据。

注意，MVCC和类似HBase之类的行版本没有达到这种级别的人为错误容忍度。MVCC和HBase行版本不会永远保留旧数据：一旦数据库compact行，旧数据就没了。只有不可变数据库保证了，当坏数据写入时有法儿恢复。


实时层
不管信不信，批处理已经解决了实时的在任意数据上做任意计算的全部问题。几小时前的数据已经可以出现在查询结果中了，现在要做的是补上最近几小时的数据。想法在最近几小时的数据上做实时查询，比在全部数据上做同样的查询要简单多了（因为数据集很小），这个见解是决定性的。

为了补上最近几小时的数据，需要一个实时系统和批处理系统并行存在。实时系统预计算最近几小时的数据。为了完成一个查询，需要同时查批处理的和实时计算出的结果，然后合并它们，得到最终结果。

<img src="http://nathanmarz.com/storage/batch_realtime_merge.png?__SQUARESPACE_CACHEVERSION=1318379004250">

实时层需要使用Riak或Cassandra这样的读写数据库，它依赖增量算法更新这些库中的数据。

在实时计算中充当Hadoop的是Storm，我开发了Storm，它可以实时处理大量数据，并且是可扩展的，健壮的。Storm 一直在流数据上执行运算。

回到刚才的例子，看看假如了实时层后的样子。

<img src="http://nathanmarz.com/storage/batch_realtime_example.png?__SQUARESPACE_CACHEVERSION=1318379033834">

批处理和以前一样，批处理过程基于Hadoop和ElephantDB，预计算除最近几小时外所有数据的查询。剩下的构建实时系统补上最近几小时的数据。

我们使用Cassandra存最近几小时的状态，使用Storm处理页面访问数据流，并行的把它们更新到库中。每个页面访问是个计算器在Cassandra中递增，其中key是 [URL, hour]。这就是所有了，Storm 让这一切非常简单。


批处理+实时处理，CAP，和人为错误容忍
在某种程度似乎又回到了原点，实现实时查询需要NoSQL数据库和增量算法。这意味着我们又回到了值分叉，时钟向量和读修复的复杂世界。

但是这里有个关键不同。因为实时层只是补上最近几小时的数据。最终，实时层做的每个计算都会被批处理的结果覆盖。所以，如果你犯了错或者实时层出了错，批处理层都会修复它。所有的复杂性都是暂时的。

这不意味着你不需要关心实时层的读修复和最终一致性，你仍需要尽可能的让它一致。但是当你犯错是，你不会永久的破坏你的数据，这把复杂性这个最大的负担从你肩头挪走 。

在批处理层，你只需要关心数据和数据之上的函数。这层很容易构建。另一方面，在实时层，你需要使用增量算法和非常复杂的NoSQL数据库。把所有复杂性隔离到实时层，相比构建健壮，可靠的系统，要简单很多。

另外，实时层也没有影响人为错误容忍度。在批处理层追加不可变数据仍然是整个系统的核心，和以前一样，任何错误都会在批处理层被修复。

让我分享下我的亲身经历，隔离实时层的复杂度带来的巨大好处。我有个系统非常类似于刚才描述的。Hadoop和ElephantDB在批处理层，Storm和Cassandra在实时层，因为缺乏监控，一觉醒来发现Cassandra的磁盘满了，所有的请求都超时。这导致Storm拓扑失败，流数据拥塞在队列里，同样的数据不停的重复计算（重复失败）。

如果没有批处理层，我不得不被迫扩容和恢复Cassandra。这是很常见的，更糟糕的是，同样的数据重放很多次导致数据库中的数据不准确。

幸好，所有的复杂性被隔离在了我的实时层。我只需把拥塞的队列刷到批处理层，清空Cassandra。批处理层像一个时钟装置，每隔几小时，一切就回到正常状态。没有数据丢失，查询也没有不准确。


垃圾回收
本文描述的方法有个基础，数据是不可变的，数据量持续增长。如果数据大到即使水平扩展，长期存储所有数据也是不实际的，该怎么办？（就算能存，批处理也不一定算的过来），前面描述的模型还好使吗？

很容易用“垃圾回收”扩展上面的模型。垃圾回收是一个简单的运行在所有数据集上的函数，得到一个过滤后的数据集。你可以使用任何策略来做垃圾回收。你可以模拟可变数据，只保留某项的最后一个数据，或者为每一项保留一个历史记录。例如，你可以保留一个人一年的位置记录。事实上，可变数据是垃圾回收的一种僵化形式而已（只是它不能很好处理CAP）。

垃圾处理可以用批处理实现。你可以定时运行，比如一月一次。因为垃圾回收是作为离线批处理运行的，它不影响上面的系统和CAP的关系。


结论
CAP理论让构建可扩展数据系统变得困难，根源在于，增量算法和可变状态带来的复杂性。只是，最近兴起的分布式数据库系统，让这种复杂性失控了。但是复杂性是客观存在 。

在文章开头，我说要挑战关于如何如何构建数据系统的基础假设，我把CRUD变成CR，把持久性分成批处理和实时处理，并痴迷于人为错误相容。有过去多年辛勤努力得来的经验，我才得以打破我老的将设，得到这些结论。

批处理/流处理架构还有很多有趣的能力，我还没讲。很值得总结一些。

* 算法灵活性。 一些算法很难实现增量计算。例如unique计数，当unique集合变得很大时，这是个很大的挑战。批处理/实时处理，给你灵活性，在批处理层做精确计算，在实时层做近似计算。批处理层不断覆盖实时层的结果，来修正近似结果，系统展现出“最终准确性”。
* 模式变更很容易：模式变更很难的日子一去不复返。因为批处理是整个系统的核心，很容易在整个数据集上做操作。这使得很容易更改数据模式或者数据视图。
* 特定分析更容易：批处理层的任意性，意味着你可以在数据上做任何查询。因为所有数据都可以在一个地方访问，特定分析很容易，方便。
* 自审计的：把数据看成不可变的，你得到了自审计的数据集。数据记下了它的历史。我已经讨论过，这对人为容错度的重要性，但对分析也相当有用。

我并没有声称解决了大数据领域的问题，但是我指定了思考大数据的框架。批处理/流处理架构相当通用，可以用在任何数据系统里。我并没有给你鱼或者鱼钩，而是给你展示了如何制作可以在任何水域钓任何鱼的鱼钩。

为解决大数据问题，还有很多工作要做，以提高我们的集体能力。下面是一些改进的关键领域：

* 为批量写，随机读数据库扩展数据模型：不是所有应用都可以用key/value数据模型支持的。这是我啥我们团队致力于扩展ElephantDB，使其支持搜索，文档数据库，范围查询等。
* 更好的批处理原语：Hadoop 并不是批量计算的全部。对特定的某些计算，它可能不够高效。Spark是一个重要项目，它做了一些有意思的工作来扩展MapReduce范式。
* 高层抽象：未来工作中，一个很有意思的领域是，对批处理组件和实时处理组件做高层抽象。批处理/实时处理架构如此健壮，没理由不使用更简洁的陈述式语言。

很多人想要可扩展的关系数据库，我希望此文能让你认识到，你根本不许要它。大数据和NoSQL似乎使得数据管理，相交于关系数据库更加复杂，但那只是因为你试图用和关系数据库相同的方法（通过合并数据和视图，并且依赖增量算法）来对待大数据。大数据的扩展性让你以完全不同的方式构建系统。通过把存储持续增长的不可变数据集，和重新计算作为核心，大数据系统比关系系统更容易，并且可扩展。
